{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96160315-d37a-4f35-a2a1-49619eb027ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-19T21:09:46.476734Z",
     "iopub.status.busy": "2025-07-19T21:09:46.476236Z",
     "iopub.status.idle": "2025-07-19T21:09:46.652985Z",
     "shell.execute_reply": "2025-07-19T21:09:46.652320Z",
     "shell.execute_reply.started": "2025-07-19T21:09:46.476697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::372344071344:role/service-role/AmazonSageMaker-ExecutionRole-20250720T013634'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8556152f-0cea-4bfc-9c24-49f396361b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T06:57:29.514697Z",
     "iopub.status.busy": "2025-07-20T06:57:29.514055Z",
     "iopub.status.idle": "2025-07-20T06:57:30.328988Z",
     "shell.execute_reply": "2025-07-20T06:57:30.327853Z",
     "shell.execute_reply.started": "2025-07-20T06:57:29.514665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'career_opportunities': 0, 'client_testimonials': 1, 'company_overview': 2, 'connect_to_agent': 3, 'contact_info': 4, 'feedback_or_complaint': 5, 'goodbye': 6, 'greeting': 7, 'industries_served': 8, 'mobile_app_development': 9, 'pricing_or_estimation': 10, 'process_or_methodology': 11, 'salesforce_services': 12, 'service_inquiry': 13, 'tech_stack_info': 14, 'voicemail': 15, 'web_app_development': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_169/4027273205.py:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('s3://algoworks-assistant-intent-training/training-data/algoworks_intent_training_data_20250720.csv')\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['intent'])\n",
    "\n",
    "# Save label mappings\n",
    "id2label = {i: label for i, label in enumerate(le.classes_)}\n",
    "label2id = {label: i for i, label in enumerate(le.classes_)}\n",
    "\n",
    "# Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['utterance'], df['label'], test_size=0.1)\n",
    "print(label2id)\n",
    "# Tokenize\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
    "\n",
    "# Dataset class\n",
    "class IntentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) for key, val in self.encodings.items()\n",
    "        } | {\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "train_dataset = IntentDataset(train_encodings, list(train_labels))\n",
    "val_dataset = IntentDataset(val_encodings, list(val_labels))\n",
    "\n",
    "# Load model and inject label mappings ðŸ”¥\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=len(le.classes_),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    # evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    # load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Optional accuracy metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return {'accuracy': accuracy_score(labels, predictions)}\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "612d8a0f-be91-4be2-bbd9-fb15f1599976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T04:52:19.310813Z",
     "iopub.status.busy": "2025-07-20T04:52:19.310545Z",
     "iopub.status.idle": "2025-07-20T05:00:29.147091Z",
     "shell.execute_reply": "2025-07-20T05:00:29.146442Z",
     "shell.execute_reply.started": "2025-07-20T04:52:19.310792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='368' max='368' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [368/368 08:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.733300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.773300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.592800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.663400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.137900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.906600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.652700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.625200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.364700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.211800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.059900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.869200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.904300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.725700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.426600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.453200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.287300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.196600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.088800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.062900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.115800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.066800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=368, training_loss=0.820489254820606, metrics={'train_runtime': 488.2672, 'train_samples_per_second': 6.005, 'train_steps_per_second': 0.754, 'total_flos': 17452072510728.0, 'train_loss': 0.820489254820606, 'epoch': 4.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2d2a931-db2e-4cfd-987b-92db2608f9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T05:06:28.424403Z",
     "iopub.status.busy": "2025-07-20T05:06:28.423749Z",
     "iopub.status.idle": "2025-07-20T05:06:28.600269Z",
     "shell.execute_reply": "2025-07-20T05:06:28.599380Z",
     "shell.execute_reply.started": "2025-07-20T05:06:28.424375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Who are the leaders in algoworks' => company_overview\n",
      "'where is the head office' => contact_info\n",
      "'Hello' => greeting\n",
      "'any open roles?' => career_opportunities\n"
     ]
    }
   ],
   "source": [
    "sample_utterances = [\n",
    "    \"Who are the leaders in algoworks\",\n",
    "    \"where is the head office\",\n",
    "    \"Hello\",\n",
    "    \"any open roles?\"\n",
    "]\n",
    "\n",
    "for text in sample_utterances:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    pred_id = outputs.logits.argmax().item()\n",
    "    intent = le.inverse_transform([pred_id])[0]\n",
    "    print(f\"'{text}' => {intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298c64c-9a8a-4e8e-8240-cdbdf943af4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T05:06:36.126085Z",
     "iopub.status.busy": "2025-07-20T05:06:36.125513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved with label mappings embedded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 117.0 MiB/235.7 MiB (231.8 MiB/s) with 1 file(s) remaining"
     ]
    }
   ],
   "source": [
    "# Save final model ðŸ”¥ with intent names\n",
    "model_dir = \"trained-models\"\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "print(\"âœ… Model saved with label mappings embedded.\")\n",
    "!tar czf algoworks_intent_model_20250720.tar.gz -C $model_dir .\n",
    "!aws s3 cp algoworks_intent_model_20250720.tar.gz s3://algoworks-assistant-intent-training/trained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622596c-ecc2-4adc-8f86-c951227cb41c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T06:59:48.345868Z",
     "iopub.status.busy": "2025-07-20T06:59:48.345511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data='s3://algoworks-assistant-intent-training/trained-models/algoworks_intent_model_20250720.tar.gz',\n",
    "   role=role,\n",
    "   transformers_version='4.26',\n",
    "   pytorch_version='1.13',\n",
    "   py_version='py39',\n",
    "   env={\n",
    "       'HF_TASK':'text-classification'\n",
    "   }\n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type='ml.t2.medium'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e999edf3-afa3-4db0-a4e7-7935a960ed1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T06:58:53.416497Z",
     "iopub.status.busy": "2025-07-20T06:58:53.415721Z",
     "iopub.status.idle": "2025-07-20T06:58:53.546992Z",
     "shell.execute_reply": "2025-07-20T06:58:53.546372Z",
     "shell.execute_reply.started": "2025-07-20T06:58:53.416470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'bios_password_reset', 'score': 0.14260870218276978}]\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict({\n",
    "    \"inputs\": \"connect to agent\"\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40761940-4b1b-4b53-8f40-c736fb3a33bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
